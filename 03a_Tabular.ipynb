{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3a Tabular.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDa9ZUtugSSo",
        "colab_type": "text"
      },
      "source": [
        "# Notebook 3a: Tabular Data\n",
        "\n",
        "This notebook will go over how the new API operates on Tabular data with the standard API, and 3b will go over utilizing RAPIDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG_kYmqLgkkC",
        "colab_type": "text"
      },
      "source": [
        "First let's install the library again, we won't need Pillow for this one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZGnJ1U1gINu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e3381152-2538-48ab-9034-26cba4c64cb9"
      },
      "source": [
        "!pip3 install torch===1.3.0 torchvision===0.4.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install git+https://github.com/fastai/fastai_dev > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision===0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/23/d418c9102d4054d19d57ccf0aca18b7c1c1f34cc0a136760b493f78ddb06/torchvision-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.3.0) (1.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.4.1) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision===0.4.1) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision===0.4.1) (0.46)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.3.0+cu100\n",
            "    Uninstalling torch-1.3.0+cu100:\n",
            "      Successfully uninstalled torch-1.3.0+cu100\n",
            "  Found existing installation: torchvision 0.4.1+cu100\n",
            "    Uninstalling torchvision-0.4.1+cu100:\n",
            "      Successfully uninstalled torchvision-0.4.1+cu100\n",
            "Successfully installed torch-1.3.0 torchvision-0.4.1\n",
            "  Running command git clone -q https://github.com/fastai/fastai_dev /tmp/pip-req-build-83oni8j3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73bJoxqSg7NN",
        "colab_type": "text"
      },
      "source": [
        "To use the tabular libraries, we need to import the `core` module. Along with this we will need some code borrowed from [notebook 41](github/fastai/fastai_dev/blob/master/dev/41_tabular_model.ipynb) to build our Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh7GKkNWgoLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.torch_basics import *\n",
        "from fastai2.basics import *\n",
        "from fastai2.tabular.core import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7djwxMSdhbwC",
        "colab_type": "text"
      },
      "source": [
        "We'll be using the ADULT's `datafram` as per usual, with our old variable setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deZVo_nWhaRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAqvC_2hnKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [Categorify, FillMissing, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSHjvS_5hu5M",
        "colab_type": "text"
      },
      "source": [
        "Now let's get into the new stuff. So before, we had something like the following to create a `TabularList`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ui40qH4hq-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### DO NOT RUN! JUST FOR SHOW OF HOW THE 1.0 API LOOKED ###\n",
        "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "                           .split_by_idx(list(range(800,1000)))\n",
        "                           .label_from_df(cols=dep_var)\n",
        "                           .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlzwUG-TiM-i",
        "colab_type": "text"
      },
      "source": [
        "Where essentially we build our `TabularList`, then choose how to split, then label, then databunch it. Quite a convoluted setup there. Let's see how the new API looks and handles it!\n",
        "\n",
        "We can still use our old procs, but now let's introduce you to the `RandomSplitter`. This function will split our dataframe's indexes randomly into 80/20. We just make a function call to it and then pass in a range we'd like to use. \n",
        "\n",
        "We'll use the `range_of` function that was made to grab the range our `dataframe` has"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoUbRwIPiWFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = RandomSplitter()(range_of(df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFAQCTFhiwv8",
        "colab_type": "text"
      },
      "source": [
        "But what is `range_of` doing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VImcFP4riu7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5abfd120-ba24-4ee9-a4bc-cb1cac8cb0b2"
      },
      "source": [
        "rang = range_of(df); \n",
        "print(rang[:10], rang[-10:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [32551, 32552, 32553, 32554, 32555, 32556, 32557, 32558, 32559, 32560]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7YQ5i44jlhH",
        "colab_type": "text"
      },
      "source": [
        "And we can see that split then randomly split our index's into two lists! (the first value here is the length of the list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6-kigzjkKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2d24fd4-ec4b-405e-e3ae-2a142012f802"
      },
      "source": [
        "splits"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((#26049) [9386,14109,10181,7992,22718,22572,25177,6876,11364,18308...],\n",
              " (#6512) [23673,24687,1608,28424,4770,6716,19149,31006,1982,14778...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsYOxiMPi5Do",
        "colab_type": "text"
      },
      "source": [
        "Well, it's a list of indexes our dataframe has in it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgW1Fl3YjHyM",
        "colab_type": "text"
      },
      "source": [
        "Great! So what's next? \n",
        "\n",
        "Now we can create a `TabularPandas` object! Think of it like our `TabularList` with a bit more parameters. We pass in the `dataframe`, our preprocessor steps (`procs`), our categorical and continuous variables, our `y` variable, and how we want to split our data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UKInJ73izvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names, y_names=\"salary\",\n",
        "                   splits=splits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwieTvivj0eY",
        "colab_type": "text"
      },
      "source": [
        "Along with this there is an optional `is_y_cat`, which will determine if you want a regression problem or not.\n",
        "\n",
        "So what is this `TabularPandas` object? Think of it like a Pandas Dataframe enhanced! We can use it a bit like a regular one, but yet it's already split and prepared to databunch!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYMT3cvnkyXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "2581f16a-e4ff-4299-856c-f0e1a6982924"
      },
      "source": [
        "to.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>salary</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9386</th>\n",
              "      <td>0.104522</td>\n",
              "      <td>6</td>\n",
              "      <td>1.469168</td>\n",
              "      <td>15</td>\n",
              "      <td>1.928576</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14109</th>\n",
              "      <td>0.691071</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.323401</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.029405</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10181</th>\n",
              "      <td>1.204301</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.129143</td>\n",
              "      <td>11</td>\n",
              "      <td>2.320172</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1977</td>\n",
              "      <td>55</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7992</th>\n",
              "      <td>1.277620</td>\n",
              "      <td>5</td>\n",
              "      <td>0.727911</td>\n",
              "      <td>10</td>\n",
              "      <td>1.145383</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22718</th>\n",
              "      <td>1.204301</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.503648</td>\n",
              "      <td>10</td>\n",
              "      <td>1.145383</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  workclass    fnlwgt  ...  age_na  fnlwgt_na  education-num_na\n",
              "9386   0.104522          6  1.469168  ...       1          1                 1\n",
              "14109  0.691071          5 -0.323401  ...       1          1                 1\n",
              "10181  1.204301          5 -0.129143  ...       1          1                 1\n",
              "7992   1.277620          5  0.727911  ...       1          1                 1\n",
              "22718  1.204301          3 -1.503648  ...       1          1                 1\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr1hO2I9kkiq",
        "colab_type": "text"
      },
      "source": [
        "## DataBunch\n",
        "\n",
        "We can create our `DataBunch` object a few different ways. The first I'll show you is very high-level and helps using defaults. Our `tp` object has a list of train and validation in it, so the last step is to simply `.databunch()` it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtGscp_HlE6N",
        "colab_type": "text"
      },
      "source": [
        "### Method 1: Straight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZPBknTxlHLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = to.databunch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s60gkn7KlKKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "b6deb627-5813-4cb2-b372-ea1982e6f5b6"
      },
      "source": [
        "dbunch.show_batch()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>29521.994539</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>467107.990769</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>119703.999997</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.999999</td>\n",
              "      <td>54824.997941</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>68.000001</td>\n",
              "      <td>270338.996935</td>\n",
              "      <td>6.0</td>\n",
              "      <td>?</td>\n",
              "      <td>10th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>46.000000</td>\n",
              "      <td>459189.009275</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>56582.000487</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>173779.999996</td>\n",
              "      <td>10.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>266336.998972</td>\n",
              "      <td>9.0</td>\n",
              "      <td>?</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>263772.998810</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2qVVvW4lLxU",
        "colab_type": "text"
      },
      "source": [
        "### Method 2: With Two DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UiZxrtnkAwx",
        "colab_type": "text"
      },
      "source": [
        "We can create our `DataLoaders` (a train and a valid). One great reason to do this *this* way is we can pass in different batch sizes into each `TabDataLoader`, along with changing options like `shuffle` and `drop_last` (at the bottom I'll show why that's **super** cool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yElrztzkgjg",
        "colab_type": "text"
      },
      "source": [
        "So how do we use it? Our train and validation data live in `tp.train` and `tp.valid` right now, so we specify that along with our options. When you make a training `DataLoader`, you want `shuffle` to be `True` and `drop_last` to be `True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG76wM4rj82T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dl = TabDataLoader(to.train, bs=64, shuffle=True, drop_last=True)\n",
        "val_dl = TabDataLoader(to.valid, bs=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frHNHLvClqEM",
        "colab_type": "text"
      },
      "source": [
        "Since our validation dataset is much smaller, we can have a larger batch size here. Now let's create a `DataBunch`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soC9roE9lpO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = DataBunch(trn_dl, val_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGhQWUW0lwRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "ce0416b6-1b9a-450c-9799-f8f803edb5a7"
      },
      "source": [
        "dbunch.show_batch()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.0</td>\n",
              "      <td>117982.996926</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.0</td>\n",
              "      <td>270543.997075</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>12th</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32.0</td>\n",
              "      <td>285131.000281</td>\n",
              "      <td>12.0</td>\n",
              "      <td>?</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.0</td>\n",
              "      <td>349151.005482</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37.0</td>\n",
              "      <td>76766.997150</td>\n",
              "      <td>15.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31.0</td>\n",
              "      <td>304212.000533</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20.0</td>\n",
              "      <td>211293.000575</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>51.0</td>\n",
              "      <td>87205.001406</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27.0</td>\n",
              "      <td>214384.999293</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26.0</td>\n",
              "      <td>89389.000849</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCv9I3-Xl6h7",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Great! Let's train a model. I'm going to put in the code we need in a seperate bit here but nothing has changed since 1.0 in terms of the embedding rule and model generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy06rBebmD2G",
        "colab_type": "text"
      },
      "source": [
        "### Source Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU_Ps8jrlxNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emb_sz_rule(n_cat): \n",
        "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
        "    return min(600, round(1.6 * n_cat**0.56))\n",
        "\n",
        "def _one_emb_sz(classes, n, sz_dict=None):\n",
        "    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
        "    sz_dict = ifnone(sz_dict, {})\n",
        "    n_cat = len(classes[n])\n",
        "    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
        "    return n_cat,sz\n",
        "\n",
        "def get_emb_sz(to, sz_dict=None):\n",
        "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
        "    return [_one_emb_sz(to.procs.classes, n, sz_dict) for n in to.cat_names]\n",
        "\n",
        "class TabularModel(Module):\n",
        "    \"Basic model for tabular data.\"\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=None, embed_p=0., y_range=None, use_bn=True, bn_final=False):\n",
        "        ps = ifnone(ps, [0]*len(layers))\n",
        "        if not is_listy(ps): ps = [ps]*len(layers)\n",
        "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "        self.emb_drop = nn.Dropout(embed_p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
        "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
        "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
        "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
        "        _layers = [BnDropLin(sizes[i], sizes[i+1], bn=use_bn and i!=0, p=p, act=a)\n",
        "                       for i,(p,a) in enumerate(zip([0.]+ps,actns))]\n",
        "        if bn_final: _layers.append(nn.BatchNorm1d(sizes[-1]))\n",
        "        self.layers = nn.Sequential(*_layers)\n",
        "    \n",
        "    def forward(self, x_cat, x_cont):\n",
        "        if self.n_emb != 0:\n",
        "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
        "            x = torch.cat(x, 1)\n",
        "            x = self.emb_drop(x)\n",
        "        if self.n_cont != 0:\n",
        "            x_cont = self.bn_cont(x_cont)\n",
        "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
        "        x = self.layers(x)\n",
        "        if self.y_range is not None:\n",
        "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_fg8-zxmRyl",
        "colab_type": "text"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Eventually something similar to `tabular_learner` will appear, but for the time being we need to build the model ourselves. We do this by calling `TabularModel` and passing in an embedding matrix size, how many continuous variables we have, our number of outputs, and our layer sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beJIUnyVmijr",
        "colab_type": "text"
      },
      "source": [
        "We can gather our embedding matrix by doing `get_emb_sz` and passing in a `TabularPandas`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50sq0ZmMmQdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_szs = get_emb_sz(to)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axhtHS4emtDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72853899-5fc3-48f9-af1c-a1d20856f54b"
      },
      "source": [
        "emb_szs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, 6), (17, 8), (8, 5), (16, 8), (7, 5), (6, 4), (2, 2), (2, 2), (3, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p117GDPm6Nq",
        "colab_type": "text"
      },
      "source": [
        "We can grab our number of continous variables by calling a `cont_names` to our tabular pandas object as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QkZiZ1rm5OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dea969f8-4f4d-49a1-e417-049427f91185"
      },
      "source": [
        "cont_len = len(to.cont_names); cont_len"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSG5DwyvmwHA",
        "colab_type": "text"
      },
      "source": [
        "Now that we have these, let's create our model! We'll use a simple `[200, 100]` layer setup like Jeremy has in his lectures. We'll also want to have our output be `2`, as this is binary classification (Above or below $50k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV1VouB3mvnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = TabularModel(emb_szs, cont_len, 2, [200,100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBVMwyELnM_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4ccc7442-c4b9-45c8-fd5f-4ac149754169"
      },
      "source": [
        "net"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(10, 6)\n",
              "    (1): Embedding(17, 8)\n",
              "    (2): Embedding(8, 5)\n",
              "    (3): Embedding(16, 8)\n",
              "    (4): Embedding(7, 5)\n",
              "    (5): Embedding(6, 4)\n",
              "    (6): Embedding(2, 2)\n",
              "    (7): Embedding(2, 2)\n",
              "    (8): Embedding(3, 3)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): BnDropLin(\n",
              "      (0): Linear(in_features=46, out_features=200, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BnDropLin(\n",
              "      (0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=200, out_features=100, bias=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BnDropLin(\n",
              "      (0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=100, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h8YOTJonSvI",
        "colab_type": "text"
      },
      "source": [
        "Now let's create an optimizer instance, our `Learner` object, and start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcc7uN9gncNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, wd=0.01, eps=1e-5)\n",
        "learn = Learner(dbunch, net, CrossEntropyLossFlat(), opt_func=opt_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOe2p56njoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7751b23a-bc6d-4820-8292-d52e5df9c0bb"
      },
      "source": [
        "learn.fit(1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#5) [0,0.37234917283058167,0.35412687063217163,0.8353808522224426,00:10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb9FW1_gn2B7",
        "colab_type": "text"
      },
      "source": [
        "Awesome! We get ~82.5% accuracy! We can call `learn.show_results` to take a look at a dataframe that shows our predictions (something new!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1aSZj-Mp6-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "@typedispatch\n",
        "def show_results(x:Tabular, y:Tabular, samples, outs, ctxs=None, max_n=10, **kwargs):\n",
        "    df = x.all_cols[:max_n]\n",
        "    df[to.y_names+'_pred'] = y[to.y_names][:max_n].values\n",
        "    display_df(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsmWqprLrJyk",
        "colab_type": "text"
      },
      "source": [
        "And if you notice *how* they did it, it looks just like adding a column to a `DataFrame`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM_k3heEnlwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "952cae0d-d12d-4896-a3f8-d0b0f8bb8e1c"
      },
      "source": [
        "learn.show_results()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "      <th>salary</th>\n",
              "      <th>salary_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46.0</td>\n",
              "      <td>207300.999331</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.0</td>\n",
              "      <td>419052.993722</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61.0</td>\n",
              "      <td>195518.999819</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>Masters</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52.0</td>\n",
              "      <td>334273.003392</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.0</td>\n",
              "      <td>227855.999994</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17.0</td>\n",
              "      <td>168202.999963</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>7th-8th</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Other</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>45.0</td>\n",
              "      <td>213140.000239</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>10th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>49.0</td>\n",
              "      <td>203039.000464</td>\n",
              "      <td>7.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>11th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>54.0</td>\n",
              "      <td>123010.998709</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&gt;=50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>33.0</td>\n",
              "      <td>171214.999849</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>&lt;50k</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvLfzG-qrV60",
        "colab_type": "text"
      },
      "source": [
        "# That Cool Bit I Mentioned Earlier\n",
        "\n",
        "One neat thing we can do now is have labeled test sets, and its easy to do! Let's create a labeled test set with our validation dataset from earlier (in practice you'd want a second labeled test set you'd want to use!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FHrFidlrp02",
        "colab_type": "text"
      },
      "source": [
        "We're going to create a `TabularPandas` object like before: (using the whole `DataFrame`) and then we can create a `DataLoader` like before too, specifying `shuffle` to `False` and `drop_last` to `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnjOnnUTrF15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_test = TabularPandas(df, procs, cat_names, cont_names, y_names=\"salary\")\n",
        "test_dl = TabDataLoader(to_test, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5RXxu0sAgM",
        "colab_type": "text"
      },
      "source": [
        "And now we can pass in any `DataLoader` right into `learn.get_preds()` **or** `learn.validate()`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0bd8bFjrtyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "415a49a3-079f-4d33-ad53-f74729ea6b0e"
      },
      "source": [
        "learn.validate(dl=test_dl)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [0.35304903984069824,0.836675763130188]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhcsVDGzsKXo",
        "colab_type": "text"
      },
      "source": [
        "If you're worried about if it's actually working or not, let's get our predictions and check them ourselves with `get_preds`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2lA99wMsJbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = learn.get_preds(dl=test_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYE7K7XrsSbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39191561-816b-4a5a-fbb3-f4bab5ec94d4"
      },
      "source": [
        "accuracy(preds[0], preds[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajHVHJdxsU1P",
        "colab_type": "text"
      },
      "source": [
        "You can see that they line up perfectly!\n",
        "\n",
        "Thanks for reading, and I hope you enjoy the v2 library as much as I am :)"
      ]
    }
  ]
}
