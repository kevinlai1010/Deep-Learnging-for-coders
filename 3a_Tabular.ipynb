{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3a Tabular.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDa9ZUtugSSo",
        "colab_type": "text"
      },
      "source": [
        "# Notebook 3a: Tabular Data\n",
        "\n",
        "This notebook will go over how the new API operates on Tabular data with the standard API, and 3b will go over utilizing RAPIDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG_kYmqLgkkC",
        "colab_type": "text"
      },
      "source": [
        "First let's install the library again, we won't need Pillow for this one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZGnJ1U1gINu",
        "colab_type": "code",
        "outputId": "2ea09495-4756-43fe-d6a1-60e5a9d9cc78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch torchvision feather-format kornia pyarrow Pillow wandb --upgrade \n",
        "!pip install git+https://github.com/fastai/fastprogress  --upgrade\n",
        "!pip install git+https://github.com/fastai/fastai_dev    "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already up-to-date: feather-format in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Collecting kornia\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/05/4adc0140932d37ab1ff02f3a88c3362d5d31b999936bb3af651f641e1295/kornia-0.1.4.post2-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 41.4MB/s \n",
            "\u001b[?25hCollecting pyarrow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/32/ce1926f05679ea5448fd3b98fbd9419d8c7a65f87d1a12ee5fb9577e3a8e/pyarrow-0.15.1-cp36-cp36m-manylinux2010_x86_64.whl (59.2MB)\n",
            "\u001b[K     |████████████████████████████████| 59.2MB 152kB/s \n",
            "\u001b[?25hCollecting Pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 63.2MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/bd/3909f10c9986d93c82c9ab8899f8002ed01f57ca597607a41955c403b86e/wandb-0.8.15-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 62.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.0MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/d7/89536db7654f2636549a10d85a918feefd9aa2cac0929dd6796c8e945e78/sentry_sdk-0.13.2-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.9MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 73.3MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n",
            "Collecting gql>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2019.9.11)\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[?25hCollecting graphql-core>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/11/bc4a7eb440124271289d93e4d208bd07d94196038fabbe2a52435a07d3d3/graphql_core-2.2.1-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 70.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
            "Collecting argh>=0.24.1\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Collecting rx<3,>=1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 65.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: subprocess32, shortuuid, gql, watchdog, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=50c109667fe74b1ab80e43bcb985c45229f44cbc979e111ddc7b257823698fed\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=d75d3deb31094b12727733f1944166ff9884b53fc8565a3407d9fd6e54e8ad63\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.1.0-cp36-none-any.whl size=5541 sha256=bb1d112e0a48005711471553f9c03ffe337a3db0c2b3a191b3fa5af8e0f4eb38\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=17f40825682c404511f9118eb8341ef78767c5bd662e01cf06813b76befc0c12\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=b9533822c564372630c1c39d54a8ccaf0f6694a156ab2d18746299dd17b10cf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 shortuuid gql watchdog pathtools\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: kornia, pyarrow, Pillow, subprocess32, sentry-sdk, smmap2, gitdb2, GitPython, docker-pycreds, shortuuid, configparser, rx, graphql-core, gql, argh, pathtools, watchdog, wandb\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: Pillow 4.3.0\n",
            "    Uninstalling Pillow-4.3.0:\n",
            "      Successfully uninstalled Pillow-4.3.0\n",
            "Successfully installed GitPython-3.0.5 Pillow-6.2.1 argh-0.26.2 configparser-4.0.2 docker-pycreds-0.4.0 gitdb2-2.0.6 gql-0.1.0 graphql-core-2.2.1 kornia-0.1.4.post2 pathtools-0.1.2 pyarrow-0.15.1 rx-1.6.1 sentry-sdk-0.13.2 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.15 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fastai/fastprogress\n",
            "  Cloning https://github.com/fastai/fastprogress to /tmp/pip-req-build-szes89vf\n",
            "  Running command git clone -q https://github.com/fastai/fastprogress /tmp/pip-req-build-szes89vf\n",
            "Building wheels for collected packages: fastprogress\n",
            "  Building wheel for fastprogress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastprogress: filename=fastprogress-0.1.22-cp36-none-any.whl size=10409 sha256=c8833f475f9b355637be54a6ef59fdd1ff3a115889c93a11bd5eec8df2511c89\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2df4omkq/wheels/7a/7b/0d/5fc197867d2d699227020d922bd8ce4b1faa75d188328f6c1c\n",
            "Successfully built fastprogress\n",
            "Installing collected packages: fastprogress\n",
            "  Found existing installation: fastprogress 0.1.21\n",
            "    Uninstalling fastprogress-0.1.21:\n",
            "      Successfully uninstalled fastprogress-0.1.21\n",
            "Successfully installed fastprogress-0.1.22\n",
            "Collecting git+https://github.com/fastai/fastai_dev\n",
            "  Cloning https://github.com/fastai/fastai_dev to /tmp/pip-req-build-l7c8yv0p\n",
            "  Running command git clone -q https://github.com/fastai/fastai_dev /tmp/pip-req-build-l7c8yv0p\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (0.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (0.25.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (2.21.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (0.1.22)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (6.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (0.21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (1.3.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2==2.0.1) (2.1.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->fastai2==2.0.1) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai2==2.0.1) (1.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==2.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==2.0.1) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==2.0.1) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==2.0.1) (2.4.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2==2.0.1) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==2.0.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==2.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==2.0.1) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==2.0.1) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2==2.0.1) (0.14.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (0.2.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (7.0.8)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (2.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==2.0.1) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai2==2.0.1) (41.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy->fastai2==2.0.1) (4.28.1)\n",
            "Building wheels for collected packages: fastai2\n",
            "  Building wheel for fastai2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastai2: filename=fastai2-2.0.1-cp36-none-any.whl size=173877 sha256=0b33a34ea160159731c598420f06a5f1db9583f0529ad7138b24666dee30a9f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6ww85kut/wheels/3e/b2/15/88c105fb1591b06b8445ff21b00f1e03d9176d22eb9f1de934\n",
            "Successfully built fastai2\n",
            "Installing collected packages: fastai2\n",
            "Successfully installed fastai2-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73bJoxqSg7NN",
        "colab_type": "text"
      },
      "source": [
        "To use the tabular libraries, we need to import the `core` module. Along with this we will need some code borrowed from [notebook 41](github/fastai/fastai_dev/blob/master/dev/41_tabular_model.ipynb) to build our Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh7GKkNWgoLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.basics import *\n",
        "from fastai2.tabular.core import *\n",
        "from fastai2.tabular.model import *\n",
        "from fastai2.callback.all import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7djwxMSdhbwC",
        "colab_type": "text"
      },
      "source": [
        "We'll be using the ADULT's `datafram` as per usual, with our old variable setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deZVo_nWhaRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "85fb54ea-e70d-47e3-c8b3-766aa02b8797"
      },
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAqvC_2hnKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [Categorify, FillMissing, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSHjvS_5hu5M",
        "colab_type": "text"
      },
      "source": [
        "Now let's get into the new stuff. So before, we had something like the following to create a `TabularList`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ui40qH4hq-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### DO NOT RUN! JUST FOR SHOW OF HOW THE 1.0 API LOOKED ###\n",
        "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "                           .split_by_idx(list(range(800,1000)))\n",
        "                           .label_from_df(cols=dep_var)\n",
        "                           .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlzwUG-TiM-i",
        "colab_type": "text"
      },
      "source": [
        "Where essentially we build our `TabularList`, then choose how to split, then label, then databunch it. Quite a convoluted setup there. Let's see how the new API looks and handles it!\n",
        "\n",
        "We can still use our old procs, but now let's introduce you to the `RandomSplitter`. This function will split our dataframe's indexes randomly into 80/20. We just make a function call to it and then pass in a range we'd like to use. \n",
        "\n",
        "We'll use the `range_of` function that was made to grab the range our `dataframe` has"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoUbRwIPiWFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = RandomSplitter()(range_of(df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFAQCTFhiwv8",
        "colab_type": "text"
      },
      "source": [
        "But what is `range_of` doing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VImcFP4riu7B",
        "colab_type": "code",
        "outputId": "375371d2-4dd2-4fc8-ec2b-0b88838afd9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rang = range_of(df); \n",
        "print(rang[:10], rang[-10:])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [32551, 32552, 32553, 32554, 32555, 32556, 32557, 32558, 32559, 32560]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7YQ5i44jlhH",
        "colab_type": "text"
      },
      "source": [
        "And we can see that split then randomly split our index's into two lists! (the first value here is the length of the list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6-kigzjkKK",
        "colab_type": "code",
        "outputId": "ab6e471e-cea1-4d95-a694-453c539549e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "splits"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((#26049) [3666,10658,4062,19410,13138,31455,9928,15554,29856,3015...],\n",
              " (#6512) [24965,9066,5774,32419,7612,10884,4617,26938,5591,28001...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsYOxiMPi5Do",
        "colab_type": "text"
      },
      "source": [
        "Well, it's a list of indexes our dataframe has in it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgW1Fl3YjHyM",
        "colab_type": "text"
      },
      "source": [
        "Great! So what's next? \n",
        "\n",
        "Now we can create a `TabularPandas` object! Think of it like our `TabularList` with a bit more parameters. We pass in the `dataframe`, our preprocessor steps (`procs`), our categorical and continuous variables, our `y` variable, and how we want to split our data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7C6CcoCfTaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TabularPandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UKInJ73izvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names, y_names=\"salary\",\n",
        "                   splits=splits, block_y=CategoryBlock)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwieTvivj0eY",
        "colab_type": "text"
      },
      "source": [
        "Along with this there is an optional `block_y`, which will determine if you want a regression problem or not. Since we are doing Categories, we do a `CategoryBlock`. If we wanted to do regression we do `type_y=Float`\n",
        "\n",
        "So what is this `TabularPandas` object? Think of it like a Pandas Dataframe enhanced! We can use it a bit like a regular one, but yet it's already split and prepared to databunch!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYMT3cvnkyXk",
        "colab_type": "code",
        "outputId": "2581f16a-e4ff-4299-856c-f0e1a6982924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "to.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>salary</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9386</th>\n",
              "      <td>0.104522</td>\n",
              "      <td>6</td>\n",
              "      <td>1.469168</td>\n",
              "      <td>15</td>\n",
              "      <td>1.928576</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14109</th>\n",
              "      <td>0.691071</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.323401</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.029405</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10181</th>\n",
              "      <td>1.204301</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.129143</td>\n",
              "      <td>11</td>\n",
              "      <td>2.320172</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1977</td>\n",
              "      <td>55</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7992</th>\n",
              "      <td>1.277620</td>\n",
              "      <td>5</td>\n",
              "      <td>0.727911</td>\n",
              "      <td>10</td>\n",
              "      <td>1.145383</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22718</th>\n",
              "      <td>1.204301</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.503648</td>\n",
              "      <td>10</td>\n",
              "      <td>1.145383</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            age  workclass    fnlwgt  ...  age_na  fnlwgt_na  education-num_na\n",
              "9386   0.104522          6  1.469168  ...       1          1                 1\n",
              "14109  0.691071          5 -0.323401  ...       1          1                 1\n",
              "10181  1.204301          5 -0.129143  ...       1          1                 1\n",
              "7992   1.277620          5  0.727911  ...       1          1                 1\n",
              "22718  1.204301          3 -1.503648  ...       1          1                 1\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr1hO2I9kkiq",
        "colab_type": "text"
      },
      "source": [
        "## DataBunch\n",
        "\n",
        "We can create our `DataBunch` object a few different ways. The first I'll show you is very high-level and helps using defaults. Our `tp` object has a list of train and validation in it, so the last step is to simply `.databunch()` it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtGscp_HlE6N",
        "colab_type": "text"
      },
      "source": [
        "### Method 1: Straight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZPBknTxlHLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = to.databunch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s60gkn7KlKKQ",
        "colab_type": "code",
        "outputId": "8002e7b2-820a-464a-e57c-9425e348b388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "dbunch.show_batch()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Private</td>\n",
              "      <td>9th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Transport-moving</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>37.0</td>\n",
              "      <td>278632.001158</td>\n",
              "      <td>5.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>30.0</td>\n",
              "      <td>159187.001329</td>\n",
              "      <td>13.0</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Local-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>44.0</td>\n",
              "      <td>203760.999509</td>\n",
              "      <td>13.0</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>19.0</td>\n",
              "      <td>343199.996435</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>#na#</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22.0</td>\n",
              "      <td>103761.998660</td>\n",
              "      <td>13.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Private</td>\n",
              "      <td>9th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Transport-moving</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>32.0</td>\n",
              "      <td>217459.999192</td>\n",
              "      <td>5.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>42.0</td>\n",
              "      <td>397345.998114</td>\n",
              "      <td>9.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>45.0</td>\n",
              "      <td>271962.003024</td>\n",
              "      <td>13.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>43.0</td>\n",
              "      <td>273230.002524</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&gt;=50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>47.0</td>\n",
              "      <td>168190.999857</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2qVVvW4lLxU",
        "colab_type": "text"
      },
      "source": [
        "### Method 2: With Two DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UiZxrtnkAwx",
        "colab_type": "text"
      },
      "source": [
        "We can create our `DataLoaders` (a train and a valid). One great reason to do this *this* way is we can pass in different batch sizes into each `TabDataLoader`, along with changing options like `shuffle` and `drop_last` (at the bottom I'll show why that's **super** cool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yElrztzkgjg",
        "colab_type": "text"
      },
      "source": [
        "So how do we use it? Our train and validation data live in `tp.train` and `tp.valid` right now, so we specify that along with our options. When you make a training `DataLoader`, you want `shuffle` to be `True` and `drop_last` to be `True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG76wM4rj82T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_dl = TabDataLoader(to.train, bs=64, shuffle=True, drop_last=True)\n",
        "val_dl = TabDataLoader(to.valid, bs=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frHNHLvClqEM",
        "colab_type": "text"
      },
      "source": [
        "Since our validation dataset is much smaller, we can have a larger batch size here. Now let's create a `DataBunch`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soC9roE9lpO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = DataBunch(trn_dl, val_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGhQWUW0lwRj",
        "colab_type": "code",
        "outputId": "5e6f4f01-099b-4218-e966-a60b7cc7cb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "dbunch.show_batch()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>age_na</th>\n",
              "      <th>fnlwgt_na</th>\n",
              "      <th>education-num_na</th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Private</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>39.0</td>\n",
              "      <td>114078.998347</td>\n",
              "      <td>12.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>34.0</td>\n",
              "      <td>261418.002062</td>\n",
              "      <td>9.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>22.0</td>\n",
              "      <td>324921.995714</td>\n",
              "      <td>9.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>51.0</td>\n",
              "      <td>268638.999576</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>32.0</td>\n",
              "      <td>195576.000038</td>\n",
              "      <td>7.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>20.0</td>\n",
              "      <td>451995.998245</td>\n",
              "      <td>9.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>41.0</td>\n",
              "      <td>118618.998681</td>\n",
              "      <td>13.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>37.0</td>\n",
              "      <td>178136.000088</td>\n",
              "      <td>9.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-spouse-absent</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>29.0</td>\n",
              "      <td>308943.995217</td>\n",
              "      <td>9.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>45.0</td>\n",
              "      <td>188329.999952</td>\n",
              "      <td>13.0</td>\n",
              "      <td>&lt;50k</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCv9I3-Xl6h7",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Great! Let's train a model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_fg8-zxmRyl",
        "colab_type": "text"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Eventually something similar to `tabular_learner` will appear, but for the time being we need to build the model ourselves. We do this by calling `TabularModel` and passing in an embedding matrix size, how many continuous variables we have, our number of outputs, and our layer sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beJIUnyVmijr",
        "colab_type": "text"
      },
      "source": [
        "We can gather our embedding matrix by doing `get_emb_sz` and passing in a `TabularPandas`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50sq0ZmMmQdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_szs = get_emb_sz(to)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axhtHS4emtDt",
        "colab_type": "code",
        "outputId": "1f653649-61a2-46a9-b73c-83ec7adde05b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_szs"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, 6), (17, 8), (8, 5), (16, 8), (7, 5), (6, 4), (2, 2), (2, 2), (3, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p117GDPm6Nq",
        "colab_type": "text"
      },
      "source": [
        "We can grab our number of continous variables by calling a `cont_names` to our tabular pandas object as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QkZiZ1rm5OE",
        "colab_type": "code",
        "outputId": "c6fcc653-8ad7-420d-ce89-d919f67f658c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cont_len = len(to.cont_names); cont_len"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSG5DwyvmwHA",
        "colab_type": "text"
      },
      "source": [
        "Now that we have these, let's create our model! We'll use a simple `[200, 100]` layer setup like Jeremy has in his lectures. We'll also want to have our output be `2`, as this is binary classification (Above or below $50k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV1VouB3mvnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = TabularModel(emb_szs, cont_len, 2, [200,100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBVMwyELnM_B",
        "colab_type": "code",
        "outputId": "b7f9c62c-294b-4c2a-a7ad-060e3ab638a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "net"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(10, 6)\n",
              "    (1): Embedding(17, 8)\n",
              "    (2): Embedding(8, 5)\n",
              "    (3): Embedding(16, 8)\n",
              "    (4): Embedding(7, 5)\n",
              "    (5): Embedding(6, 4)\n",
              "    (6): Embedding(2, 2)\n",
              "    (7): Embedding(2, 2)\n",
              "    (8): Embedding(3, 3)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): LinBnDrop(\n",
              "      (0): BatchNorm1d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=46, out_features=200, bias=False)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): LinBnDrop(\n",
              "      (0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Linear(in_features=200, out_features=100, bias=False)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): LinBnDrop(\n",
              "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h8YOTJonSvI",
        "colab_type": "text"
      },
      "source": [
        "Now let's create an optimizer instance, our `Learner` object, and start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcc7uN9gncNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, wd=0.01, eps=1e-5)\n",
        "learn = Learner(dbunch, net, CrossEntropyLossFlat(), opt_func=opt_func, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOe2p56njoo",
        "colab_type": "code",
        "outputId": "3a4cda0e-f59d-4756-e64d-43a39aa5b0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.352180</td>\n",
              "      <td>0.352489</td>\n",
              "      <td>0.841523</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb9FW1_gn2B7",
        "colab_type": "text"
      },
      "source": [
        "Awesome! We get ~82.5% accuracy! We can call `learn.show_results` to take a look at a dataframe that shows our predictions (something new!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsmWqprLrJyk",
        "colab_type": "text"
      },
      "source": [
        "And if you notice *how* they did it, it looks just like adding a column to a `DataFrame`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvLfzG-qrV60",
        "colab_type": "text"
      },
      "source": [
        "# That Cool Bit I Mentioned Earlier\n",
        "\n",
        "One neat thing we can do now is have labeled test sets, and its easy to do! Let's create a labeled test set with our validation dataset from earlier (in practice you'd want a second labeled test set you'd want to use!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FHrFidlrp02",
        "colab_type": "text"
      },
      "source": [
        "We're going to create a `TabularPandas` object like before: (using the whole `DataFrame`) and then we can create a `DataLoader` like before too, specifying `shuffle` to `False` and `drop_last` to `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnjOnnUTrF15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_test = TabularPandas(df, procs, cat_names, cont_names, y_names=\"salary\")\n",
        "test_dl = TabDataLoader(to_test, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5RXxu0sAgM",
        "colab_type": "text"
      },
      "source": [
        "And now we can pass in any `DataLoader` right into `learn.get_preds()` **or** `learn.validate()`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0bd8bFjrtyt",
        "colab_type": "code",
        "outputId": "cb88bfff-ece3-476d-c837-3c52aee56328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.validate(dl=test_dl)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [0.34851083159446716,0.837136447429657]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhcsVDGzsKXo",
        "colab_type": "text"
      },
      "source": [
        "If you're worried about if it's actually working or not, let's get our predictions and check them ourselves with `get_preds`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2lA99wMsJbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4344a50b-8154-4a51-e451-268ddb67e11c"
      },
      "source": [
        "preds = learn.get_preds(dl=test_dl)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYE7K7XrsSbn",
        "colab_type": "code",
        "outputId": "d443d151-4795-4db9-f045-98c586ff0b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(preds[0], preds[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajHVHJdxsU1P",
        "colab_type": "text"
      },
      "source": [
        "You can see that they line up perfectly!\n",
        "\n",
        "Thanks for reading, and I hope you enjoy the v2 library as much as I am :)"
      ]
    }
  ]
}